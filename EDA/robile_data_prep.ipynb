{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rosbag2_py\n",
    "import numpy as np\n",
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from sensor_msgs.msg import Image, LaserScan\n",
    "from nav_msgs.msg import Odometry\n",
    "from geometry_msgs.msg import Pose\n",
    "from rclpy.serialization import deserialize_message\n",
    "from tf2_msgs.msg import TFMessage\n",
    "from rclpy.qos import QoSProfile, QoSDurabilityPolicy\n",
    "from cv_bridge import CvBridge\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImitationLearningDataset():\n",
    "    def __init__(self, bag_file, output_dir, stop_threshold=0.0001, stop_duration_limit=4.0, max_goal_distance=3.0, get_img =  True):\n",
    "        self.bag_file = bag_file\n",
    "        self.output_dir = output_dir\n",
    "        self.bridge = CvBridge()\n",
    "        self.stop_threshold = stop_threshold\n",
    "        self.stop_duration_limit = stop_duration_limit\n",
    "        self.max_goal_distance = max_goal_distance\n",
    "        self.get_img = get_img\n",
    "\n",
    "        # Containers for data\n",
    "        self.images = []\n",
    "        self.lasers = []\n",
    "        self.odoms = []\n",
    "        self.velocities = []\n",
    "        self.tf_messages = []\n",
    "        self.tf_static_messages = []\n",
    "        self.baselink_odom_tf = []\n",
    "        self.timestamps = []\n",
    "\n",
    "        # Process messages\n",
    "        self.process_bag(bag_file)\n",
    "\n",
    "    def process_bag(self, bag_file):\n",
    "        storage_options = rosbag2_py.StorageOptions(uri=bag_file, storage_id='sqlite3')\n",
    "        converter_options = rosbag2_py.ConverterOptions(input_serialization_format='cdr', output_serialization_format='cdr')\n",
    "        reader = rosbag2_py.SequentialReader()\n",
    "        reader.open(storage_options, converter_options)\n",
    "        while reader.has_next():\n",
    "            topic, msg, t = reader.read_next()\n",
    "\n",
    "            if topic == \"/camera/color/image_raw\":\n",
    "                self.process_image(msg, t)\n",
    "            elif topic == \"/scan\":\n",
    "                self.process_laser(msg, t)\n",
    "            elif topic == \"/odom\":\n",
    "                self.process_odom(msg, t)\n",
    "            elif topic == \"/tf\":\n",
    "                self.process_tf(msg, t)\n",
    "            elif topic == \"/tf_static\":\n",
    "                self.process_tf_static(msg, t)\n",
    "\n",
    "    def process_image(self, msg, timestamp):\n",
    "        msg = deserialize_message(msg, Image)\n",
    "        cv_image = self.bridge.imgmsg_to_cv2(msg, \"bgr8\")\n",
    "        self.images.append((cv_image, timestamp))\n",
    "        self.timestamps.append(timestamp)\n",
    "\n",
    "    def process_laser(self, msg, timestamp):\n",
    "        msg_ = deserialize_message(msg, LaserScan)\n",
    "        laser_data = np.array(msg_.ranges)\n",
    "        self.lasers.append((laser_data, msg, timestamp))\n",
    "\n",
    "    def process_odom(self, msg, timestamp):\n",
    "        msg_ = deserialize_message(msg, Odometry)\n",
    "        odom_data = (msg_.pose.pose.position.x, msg_.pose.pose.position.y, msg_.pose.pose.orientation.z)\n",
    "        velocity = np.sqrt(msg_.twist.twist.linear.x**2 + msg_.twist.twist.linear.y**2)\n",
    "        self.odoms.append((odom_data, msg, timestamp))\n",
    "        self.velocities.append((velocity, msg_.twist.twist, timestamp))\n",
    "        \n",
    "    def process_tf(self, msg, timestamp):\n",
    "        self.tf_messages.append((msg, timestamp))\n",
    "        msg = deserialize_message(msg, TFMessage)\n",
    "        for transform in msg.transforms:\n",
    "            # Check if the transform is from odom to base_link\n",
    "            if transform.child_frame_id == 'base_link' and transform.header.frame_id == 'odom':\n",
    "                # Extract translation and rotation\n",
    "                translation = transform.transform.translation\n",
    "                translation = [translation.x, translation.y, translation.z]\n",
    "                rotation = transform.transform.rotation\n",
    "                rotation = [rotation.x, rotation.y, rotation.z, rotation.w]\n",
    "                self.baselink_odom_tf.append((translation, rotation,timestamp ))\n",
    "\n",
    "    def process_tf_static(self, msg, timestamp):\n",
    "        self.tf_static_messages.append((msg, timestamp))\n",
    "        \n",
    "        \n",
    "    def downsample_data(self, data, n = 4):\n",
    "        return data[::n]\n",
    "        \n",
    "    def align_data(self, interval_ns=1e8):\n",
    "        print('aligning data')\n",
    "        aligned_data = []\n",
    "        last_timestamp = None\n",
    "        \n",
    "        # Align all data based on the closest timestamp\n",
    "        for laser, laser_msg, laser_timestamp in self.lasers:\n",
    "            if last_timestamp is None or (laser_timestamp - last_timestamp) >= interval_ns: \n",
    "                if self.get_img:\n",
    "                    closest_img = min(self.images, key=lambda x: abs(x[-1] - laser_timestamp))\n",
    "                else:\n",
    "                    closest_img = [None,None]\n",
    "                closest_odom = min(self.odoms, key=lambda x: abs(x[-1] - laser_timestamp))\n",
    "                closest_vel = min(self.velocities, key=lambda x: abs(x[-1] - laser_timestamp))\n",
    "                closest_tf = min(self.baselink_odom_tf, key=lambda x: abs(x[-1] - laser_timestamp))\n",
    "                aligned_data.append([closest_img[0], [laser, laser_msg, laser_timestamp], closest_odom, closest_vel, closest_tf, laser_timestamp])\n",
    "                last_timestamp = laser_timestamp\n",
    "\n",
    "        return aligned_data\n",
    "\n",
    "    def remove_stopped_data(self):\n",
    "        moving_indices = [] \n",
    "        temp_moving_indices = []\n",
    "        stopped_time = 0\n",
    "\n",
    "        for i, (img, laser, odom, velocity, tf, timestamp, goal) in enumerate(self.aligned_data):\n",
    "            if velocity[0] > self.stop_threshold:\n",
    "                if stopped_time <= self.stop_duration_limit * 1e9:\n",
    "                    moving_indices.extend(temp_moving_indices)  \n",
    "                    temp_moving_indices = []                  \n",
    "                moving_indices.append(i)\n",
    "                stopped_time = 0\n",
    "            else:\n",
    "                stopped_time += (self.aligned_data[i][5] - self.aligned_data[i - 1][5]) if i > 0 else 0\n",
    "                if stopped_time <= self.stop_duration_limit * 1e9:\n",
    "                    temp_moving_indices.append(i)\n",
    "\n",
    "        # Filter data by moving indices\n",
    "        self.filtered_aligned_data = [self.aligned_data[i] for i in moving_indices]\n",
    "        \n",
    "    def create_dataset(self):\n",
    "        self.aligned_data = self.align_data()\n",
    "        print(len(self.aligned_data))\n",
    "        self.goal = self.calculate_goal_position(self.aligned_data)\n",
    "        self.remove_stopped_data()\n",
    "        self.aligned_data = [] \n",
    "\n",
    "    def save_dataset(self, save_bag = False):\n",
    "        \n",
    "        if save_bag:\n",
    "            self.save_filtered_bag(self.filtered_aligned_data)\n",
    "            \n",
    "        # clear up space\n",
    "        self.images = None\n",
    "        self.lasers = None\n",
    "        self.odoms = None\n",
    "        self.velocities = None\n",
    "        self.tf_messages = None\n",
    "        self.tf_static_messages = None\n",
    "        self.timestamps = None\n",
    "        self.aligned_data = None\n",
    "        \n",
    "        print('Saving as pickle files')\n",
    "    \n",
    "        # Define paths for pickle files\n",
    "        image_file = os.path.join(self.output_dir, 'images.h5')\n",
    "        laser_file = os.path.join(self.output_dir, 'lasers.pkl')\n",
    "        odom_file = os.path.join(self.output_dir, 'odoms.pkl')\n",
    "        goal_odom_file = os.path.join(self.output_dir, 'goal_odoms.pkl')\n",
    "        velocity_file = os.path.join(self.output_dir, 'velocities.pkl')\n",
    "        tf_file = os.path.join(self.output_dir, 'tfs.pkl')\n",
    "        images = []\n",
    "        lasers = []\n",
    "        current_poses = []\n",
    "        goal_poses = []\n",
    "        velocities = []\n",
    "        tfs = []\n",
    "        for img, laser, odom, velocity, tf, timestamp, goal_odom in self.filtered_aligned_data:\n",
    "            images.append(img)  # RGB images\n",
    "            lasers.append(laser[0])  # Laser ranges\n",
    "            current_poses.append(odom[0])  # Current position (x, y, orientation)\n",
    "            goal_poses.append(goal_odom[0])  # Goal position (x, y, orientation)\n",
    "            velocities.append([velocity[1].linear.x, velocity[1].linear.y, velocity[1].angular.z])  # Linear and angular velocity (x, y, z)\n",
    "            tfs.append(tf)\n",
    "\n",
    "        \n",
    "        # Save data to pickle files\n",
    "        with open(laser_file, 'wb') as f:\n",
    "            pickle.dump(lasers, f)\n",
    "        with open(odom_file, 'wb') as f:\n",
    "            pickle.dump(current_poses, f)\n",
    "        with open(goal_odom_file, 'wb') as f:\n",
    "            pickle.dump(goal_poses, f)\n",
    "        with open(velocity_file, 'wb') as f:\n",
    "            pickle.dump(velocities, f)\n",
    "        with open(tf_file, 'wb') as f:\n",
    "            pickle.dump(tfs, f)\n",
    "        if self.get_img:\n",
    "            with h5py.File(image_file, 'w') as f:\n",
    "                for index, image in enumerate(images):\n",
    "                    # Convert image to a NumPy array\n",
    "                    image_array = np.array(image)\n",
    "                    # Save image array to the HDF5 file\n",
    "                    f.create_dataset(f'image_{index}', data=image_array)\n",
    "        \n",
    "      \n",
    "\n",
    "    def calculate_goal_position(self, data):\n",
    "        # Calculate the goal position based on odometry data\\\n",
    "        for i, (_, _, init_odom, _, _, init_timestamp) in enumerate(self.aligned_data):\n",
    "            for j, (_, _, goal_odom, _,_, goal_timestamp) in enumerate(self.aligned_data[i:]):            \n",
    "                distance = np.sqrt((goal_odom[0][0] - init_odom[0][0]) ** 2 + (goal_odom[0][1] - init_odom[0][1]) ** 2)\n",
    "                if distance >= self.max_goal_distance:\n",
    "                    break\n",
    "            self.aligned_data[i].append(goal_odom)\n",
    "        \n",
    "\n",
    "    def save_filtered_bag(self, data):\n",
    "        print('Saving as bag file')\n",
    "        # Create a new bag file for the filtered data\n",
    "        output_bag_file = os.path.join(self.output_dir, \"filtered_data.bag\")\n",
    "        writer = rosbag2_py.SequentialWriter()\n",
    "\n",
    "        # Set up storage and converter options for writing\n",
    "        storage_options = rosbag2_py.StorageOptions(uri=output_bag_file, storage_id='sqlite3')\n",
    "        converter_options = rosbag2_py.ConverterOptions(input_serialization_format='cdr', output_serialization_format='cdr')\n",
    "        writer.open(storage_options, converter_options)\n",
    "        \n",
    "        qos_profile_tf_static = \"- history: 3\\n  depth: 0\\n  reliability: 1\\n  durability: 1\\n  deadline:\\n    sec: 9223372036\\n    nsec: 854775807\\n  lifespan:\\n    sec: 9223372036\\n    nsec: 854775807\\n  liveliness: 1\\n  liveliness_lease_duration:\\n    sec: 9223372036\\n    nsec: 854775807\\n  avoid_ros_namespace_conventions: false\\n- history: 3\\n  depth: 0\\n  reliability: 1\\n  durability: 1\\n  deadline:\\n    sec: 9223372036\\n    nsec: 854775807\\n  lifespan:\\n    sec: 9223372036\\n    nsec: 854775807\\n  liveliness: 1\\n  liveliness_lease_duration:\\n    sec: 9223372036\\n    nsec: 854775807\\n  avoid_ros_namespace_conventions: false\\n- history: 3\\n  depth: 0\\n  reliability: 1\\n  durability: 1\\n  deadline:\\n    sec: 9223372036\\n    nsec: 854775807\\n  lifespan:\\n    sec: 9223372036\\n    nsec: 854775807\\n  liveliness: 1\\n  liveliness_lease_duration:\\n    sec: 9223372036\\n    nsec: 854775807\\n  avoid_ros_namespace_conventions: false\"\n",
    "\n",
    "\n",
    "        # Create topics\n",
    "        writer.create_topic(rosbag2_py.TopicMetadata(name='/camera/color/image_raw', type='sensor_msgs/msg/Image', serialization_format='cdr'))\n",
    "        writer.create_topic(rosbag2_py.TopicMetadata(name='/scan', type='sensor_msgs/msg/LaserScan', serialization_format='cdr'))\n",
    "        writer.create_topic(rosbag2_py.TopicMetadata(name='/odom', type='nav_msgs/msg/Odometry', serialization_format='cdr'))\n",
    "        writer.create_topic(rosbag2_py.TopicMetadata(name='/goal_odom', type='nav_msgs/msg/Odometry', serialization_format='cdr'))\n",
    "        writer.create_topic(rosbag2_py.TopicMetadata(name='/tf', type='tf2_msgs/msg/TFMessage', serialization_format='cdr'))\n",
    "        writer.create_topic(rosbag2_py.TopicMetadata(name='/tf_static', type='tf2_msgs/msg/TFMessage', serialization_format='cdr', offered_qos_profiles=qos_profile_tf_static))\n",
    "        \n",
    "\n",
    "        # Write aligned data back to the bag\n",
    "        for img, laser, odom, velocity, _, timestamp, goal_odom in data:\n",
    "            \n",
    "\n",
    "            # Create LaserScan message\n",
    "            laser_msg = deserialize_message(laser[1], LaserScan)\n",
    "            laser_msg.header.stamp = rclpy.time.Time(seconds=timestamp * 1e-9).to_msg()\n",
    "\n",
    "            # Create Odometry message\n",
    "            odom_msg = deserialize_message(odom[1], Odometry)\n",
    "            odom_msg.header.stamp = rclpy.time.Time(seconds=timestamp * 1e-9).to_msg()\n",
    "            \n",
    "            # Create Goal Odometry message\n",
    "            goal_odom_msg = deserialize_message(goal_odom[1], Odometry)\n",
    "            goal_odom_msg.header.stamp = rclpy.time.Time(seconds=timestamp * 1e-9).to_msg()\n",
    "            \n",
    "            if self.get_img:\n",
    "                # Convert the image back to a ROS Image message\n",
    "                img_msg = self.bridge.cv2_to_imgmsg(img, \"bgr8\")\n",
    "                img_msg.header.stamp = rclpy.time.Time(seconds=timestamp * 1e-9).to_msg()\n",
    "\n",
    "                # Write messages to the new bag file\n",
    "                serialized_img = rclpy.serialization.serialize_message(img_msg)\n",
    "                writer.write('/camera/color/image_raw', serialized_img, timestamp)\n",
    "                \n",
    "            serialized_laser = rclpy.serialization.serialize_message(laser_msg)\n",
    "            writer.write('/scan', serialized_laser, timestamp)\n",
    "            serialized_odom = rclpy.serialization.serialize_message(odom_msg)\n",
    "            writer.write('/odom', serialized_odom, timestamp)\n",
    "            serialized_goal_odom = rclpy.serialization.serialize_message(goal_odom_msg)\n",
    "            writer.write('/goal_odom', serialized_goal_odom, timestamp)\n",
    "        \n",
    "        # Write tf and tf_static messages to the new bag file\n",
    "        for tf_msg, tf_timestamp in self.tf_messages:\n",
    "            writer.write('/tf', tf_msg, tf_timestamp)\n",
    "        for tf_static_msg, tf_static_timestamp in self.tf_static_messages:\n",
    "            writer.write('/tf_static', tf_static_msg, tf_static_timestamp)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329070.853818479] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr19/corr19_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "729\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329081.576153901] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr16/corr16_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "411\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329086.409781850] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr11/corr11_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "455\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329091.294019712] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr24/corr24_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "657\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329099.412622418] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr18/corr18_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "548\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329105.922292321] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr15/corr15_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "591\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329112.158215587] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr9/corr9_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "360\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329115.743918892] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr12/corr12_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "222\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329118.244161199] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr7/corr7_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "260\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329121.024331160] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr21/corr21_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "249\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329124.126891640] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr17/corr17_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "555\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329131.917142473] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr13/corr13_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "200\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329134.073141998] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr20/corr20_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "254\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329137.291978299] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr14/corr14_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "340\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329141.101949071] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr22/corr22_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "356\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329144.777209735] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr10/corr10_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "833\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329156.225786750] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr23/corr23_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "907\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329170.881794503] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr6/corr6_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "344\n",
      "Saving as pickle files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1731329174.497487923] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024/corr8/corr8_0.db3' for READ_ONLY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "270\n",
      "Saving as pickle files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_folder = '/home/nigitha/ros2_ws_rnd/src/raw_data/data_07112024'\n",
    "\n",
    "for item in os.listdir(root_folder):\n",
    "    item_path = os.path.join(root_folder, item)\n",
    "    if os.path.isdir(item_path):\n",
    "        bag_file = item_path\n",
    "        output_dir = \"/home/nigitha/ros2_ws_rnd/src/dataset/data_corr_07112024\"  # Replace with your output directory path\n",
    "        output_dir = os.path.join(output_dir, item)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        dataset_processor = ImitationLearningDataset(bag_file, output_dir, get_img= True)\n",
    "        dataset_processor.create_dataset()\n",
    "        dataset_processor.save_dataset(False)\n",
    "        del dataset_processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n",
      "3248\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving as bag file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1730282991.069719873] [rosbag2_storage]: Opened database '/home/nigitha/ros2_ws_rnd/src/dataset/corr1/downsampled/filtered_data.bag/filtered_data.bag_0.db3' for READ_WRITE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving as pickle files\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ros2_rnd_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
