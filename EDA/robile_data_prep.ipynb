{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rosbag2_py\n",
    "import numpy as np\n",
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from sensor_msgs.msg import Image, LaserScan\n",
    "from nav_msgs.msg import Odometry\n",
    "from geometry_msgs.msg import Pose\n",
    "from rclpy.serialization import deserialize_message\n",
    "from tf2_msgs.msg import TFMessage\n",
    "from tf_transformations import euler_from_quaternion\n",
    "from rclpy.qos import QoSProfile, QoSDurabilityPolicy\n",
    "from cv_bridge import CvBridge\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImitationLearningDataset():\n",
    "    def __init__(self, bag_file, output_dir, stop_threshold=0.0001, stop_duration_limit=4.0):\n",
    "        self.bag_file = bag_file\n",
    "        self.output_dir = output_dir\n",
    "        self.bridge = CvBridge()\n",
    "        self.stop_threshold = stop_threshold\n",
    "        self.stop_duration_limit = stop_duration_limit\n",
    "\n",
    "        # Containers for data\n",
    "        self.images = []\n",
    "        self.lasers = []\n",
    "        self.odoms = []\n",
    "        self.velocities = []\n",
    "        self.tf_messages = []\n",
    "        self.tf_static_messages = []\n",
    "        self.baselink_odom_tf = []\n",
    "        self.timestamps = []\n",
    "\n",
    "        # Process messages\n",
    "        self.process_bag(bag_file)\n",
    "\n",
    "    def process_bag(self, bag_file):\n",
    "        storage_options = rosbag2_py.StorageOptions(uri=bag_file, storage_id='sqlite3')\n",
    "        converter_options = rosbag2_py.ConverterOptions(input_serialization_format='cdr', output_serialization_format='cdr')\n",
    "        reader = rosbag2_py.SequentialReader()\n",
    "        reader.open(storage_options, converter_options)\n",
    "        while reader.has_next():\n",
    "            topic, msg, t = reader.read_next()\n",
    "\n",
    "            if topic == \"/camera/color/image_raw\":\n",
    "                self.process_image(msg, t)\n",
    "            elif topic == \"/scan\":\n",
    "                self.process_laser(msg, t)\n",
    "            elif topic == \"/odom\":\n",
    "                self.process_odom(msg, t)\n",
    "            elif topic == \"/tf\":\n",
    "                self.process_tf(msg, t)\n",
    "            elif topic == \"/tf_static\":\n",
    "                self.process_tf_static(msg, t)\n",
    "\n",
    "    def process_image(self, msg, timestamp):\n",
    "        msg = deserialize_message(msg, Image)\n",
    "        cv_image = self.bridge.imgmsg_to_cv2(msg, \"bgr8\")\n",
    "        self.images.append((cv_image, timestamp))\n",
    "        self.timestamps.append(timestamp)\n",
    "\n",
    "    def process_laser(self, msg, timestamp):\n",
    "        msg_ = deserialize_message(msg, LaserScan)\n",
    "        laser_data = np.array(msg_.ranges)\n",
    "        self.lasers.append((laser_data, msg, timestamp))\n",
    "\n",
    "    def process_odom(self, msg, timestamp):\n",
    "        msg_ = deserialize_message(msg, Odometry)\n",
    "        odom_data = (msg_.pose.pose.position.x, msg_.pose.pose.position.y, msg_.pose.pose.orientation.z)\n",
    "        velocity = np.sqrt(msg_.twist.twist.linear.x**2 + msg_.twist.twist.linear.y**2)\n",
    "        self.odoms.append((odom_data, msg, timestamp))\n",
    "        self.velocities.append((velocity, msg_.twist.twist, timestamp))\n",
    "        \n",
    "    def process_tf(self, msg, timestamp):\n",
    "        self.tf_messages.append((msg, timestamp))\n",
    "        msg = deserialize_message(msg, TFMessage)\n",
    "        for transform in msg.transforms:\n",
    "            # Check if the transform is from odom to base_link\n",
    "            if transform.child_frame_id == 'base_link' and transform.header.frame_id == 'odom':\n",
    "                # Extract translation and rotation\n",
    "                translation = transform.transform.translation\n",
    "                translation = [translation.x, translation.y, translation.z]\n",
    "                rotation = transform.transform.rotation\n",
    "                rotation = [rotation.x, rotation.y, rotation.z, rotation.w]\n",
    "                self.baselink_odom_tf.append((translation, rotation,timestamp ))\n",
    "\n",
    "    def process_tf_static(self, msg, timestamp):\n",
    "        self.tf_static_messages.append((msg, timestamp))\n",
    "        \n",
    "    def align_data(self):\n",
    "        print('aligning data')\n",
    "        aligned_data = []\n",
    "\n",
    "        # Align all data based on the closest timestamp\n",
    "        for img, img_timestamp in self.images:\n",
    "            closest_laser = min(self.lasers, key=lambda x: abs(x[-1] - img_timestamp))\n",
    "            closest_odom = min(self.odoms, key=lambda x: abs(x[-1] - img_timestamp))\n",
    "            closest_vel = min(self.velocities, key=lambda x: abs(x[-1] - img_timestamp))\n",
    "            closest_tf = min(self.baselink_odom_tf, key=lambda x: abs(x[-1] - img_timestamp))\n",
    "            aligned_data.append([img, closest_laser, closest_odom, closest_vel, closest_tf, img_timestamp])\n",
    "\n",
    "        return aligned_data\n",
    "\n",
    "    def remove_stopped_data(self):\n",
    "        moving_indices = [] \n",
    "        temp_moving_indices = []\n",
    "        stopped_time = 0\n",
    "\n",
    "        for i, (img, laser, odom, velocity, tf, timestamp, goal) in enumerate(self.aligned_data):\n",
    "            if velocity[0] > self.stop_threshold:\n",
    "                if stopped_time <= self.stop_duration_limit * 1e9:\n",
    "                    moving_indices.extend(temp_moving_indices)  \n",
    "                    temp_moving_indices = []                  \n",
    "                moving_indices.append(i)\n",
    "                stopped_time = 0\n",
    "            else:\n",
    "                stopped_time += (self.aligned_data[i][5] - self.aligned_data[i - 1][5]) if i > 0 else 0\n",
    "                if stopped_time <= self.stop_duration_limit * 1e9:\n",
    "                    temp_moving_indices.append(i)\n",
    "\n",
    "        # Filter data by moving indices\n",
    "        self.filtered_aligned_data = [self.aligned_data[i] for i in moving_indices]\n",
    "        \n",
    "    def create_dataset(self):\n",
    "        self.aligned_data = self.align_data()\n",
    "        self.goal = self.calculate_goal_position(self.aligned_data)\n",
    "        self.remove_stopped_data()\n",
    "\n",
    "    def save_dataset(self, save_bag = False):\n",
    "        \n",
    "        if save_bag:\n",
    "            self.save_filtered_bag(self.filtered_aligned_data)\n",
    "            \n",
    "        # clear up space\n",
    "        self.images = None\n",
    "        self.lasers = None\n",
    "        self.odoms = None\n",
    "        self.velocities = None\n",
    "        self.tf_messages = None\n",
    "        self.tf_static_messages = None\n",
    "        self.timestamps = None\n",
    "        self.aligned_data = None\n",
    "        \n",
    "        print('Saving as pickle files')\n",
    "    \n",
    "        # Define paths for pickle files\n",
    "        image_file = os.path.join(self.output_dir, 'images.h5')\n",
    "        laser_file = os.path.join(self.output_dir, 'lasers.pkl')\n",
    "        odom_file = os.path.join(self.output_dir, 'odoms.pkl')\n",
    "        goal_odom_file = os.path.join(self.output_dir, 'goal_odoms.pkl')\n",
    "        velocity_file = os.path.join(self.output_dir, 'velocities.pkl')\n",
    "        tf_file = os.path.join(self.output_dir, 'tfs.pkl')\n",
    "        images = []\n",
    "        lasers = []\n",
    "        current_poses = []\n",
    "        goal_poses = []\n",
    "        velocities = []\n",
    "        tfs = []\n",
    "        for img, laser, odom, velocity, tf, timestamp, goal_odom in self.filtered_aligned_data:\n",
    "            images.append(img)  # RGB images\n",
    "            lasers.append(laser[0])  # Laser ranges\n",
    "            current_poses.append(odom[0])  # Current position (x, y, orientation)\n",
    "            goal_poses.append(goal_odom[0])  # Goal position (x, y, orientation)\n",
    "            velocities.append([velocity[1].linear.x, velocity[1].linear.y, velocity[1].angular.z])  # Linear and angular velocity (x, y, z)\n",
    "            tfs.append(tf)\n",
    "\n",
    "        \n",
    "        # Save data to pickle files\n",
    "        with open(laser_file, 'wb') as f:\n",
    "            pickle.dump(lasers, f)\n",
    "        with open(odom_file, 'wb') as f:\n",
    "            pickle.dump(current_poses, f)\n",
    "        with open(goal_odom_file, 'wb') as f:\n",
    "            pickle.dump(goal_poses, f)\n",
    "        with open(velocity_file, 'wb') as f:\n",
    "            pickle.dump(velocities, f)\n",
    "        with open(tf_file, 'wb') as f:\n",
    "            pickle.dump(tfs, f)\n",
    "        with h5py.File(image_file, 'w') as f:\n",
    "            for index, image in enumerate(images):\n",
    "                # Convert image to a NumPy array\n",
    "                image_array = np.array(image)\n",
    "                # Save image array to the HDF5 file\n",
    "                f.create_dataset(f'image_{index}', data=image_array)\n",
    "    \n",
    "      \n",
    "\n",
    "    def calculate_goal_position(self, data):\n",
    "        # Calculate the goal position based on odometry data\n",
    "        target_distance = 1.0  # 1 meter away\n",
    "        for i, (_, _, init_odom, _, _, init_timestamp) in enumerate(self.aligned_data):\n",
    "            for j, (_, _, goal_odom, _,_, goal_timestamp) in enumerate(self.aligned_data[i:]):            \n",
    "                distance = np.sqrt((goal_odom[0][0] - init_odom[0][0]) ** 2 + (goal_odom[0][1] - init_odom[0][1]) ** 2)\n",
    "                if distance >= target_distance:\n",
    "                    break\n",
    "            self.aligned_data[i].append(goal_odom)\n",
    "        \n",
    "\n",
    "    def save_filtered_bag(self, data):\n",
    "        print('Saving as bag file')\n",
    "        # Create a new bag file for the filtered data\n",
    "        output_bag_file = os.path.join(self.output_dir, \"filtered_data.bag\")\n",
    "        writer = rosbag2_py.SequentialWriter()\n",
    "\n",
    "        # Set up storage and converter options for writing\n",
    "        storage_options = rosbag2_py.StorageOptions(uri=output_bag_file, storage_id='sqlite3')\n",
    "        converter_options = rosbag2_py.ConverterOptions(input_serialization_format='cdr', output_serialization_format='cdr')\n",
    "        writer.open(storage_options, converter_options)\n",
    "        \n",
    "        qos_profile_tf_static = \"- history: 3\\n  depth: 0\\n  reliability: 1\\n  durability: 1\\n  deadline:\\n    sec: 9223372036\\n    nsec: 854775807\\n  lifespan:\\n    sec: 9223372036\\n    nsec: 854775807\\n  liveliness: 1\\n  liveliness_lease_duration:\\n    sec: 9223372036\\n    nsec: 854775807\\n  avoid_ros_namespace_conventions: false\\n- history: 3\\n  depth: 0\\n  reliability: 1\\n  durability: 1\\n  deadline:\\n    sec: 9223372036\\n    nsec: 854775807\\n  lifespan:\\n    sec: 9223372036\\n    nsec: 854775807\\n  liveliness: 1\\n  liveliness_lease_duration:\\n    sec: 9223372036\\n    nsec: 854775807\\n  avoid_ros_namespace_conventions: false\\n- history: 3\\n  depth: 0\\n  reliability: 1\\n  durability: 1\\n  deadline:\\n    sec: 9223372036\\n    nsec: 854775807\\n  lifespan:\\n    sec: 9223372036\\n    nsec: 854775807\\n  liveliness: 1\\n  liveliness_lease_duration:\\n    sec: 9223372036\\n    nsec: 854775807\\n  avoid_ros_namespace_conventions: false\"\n",
    "\n",
    "\n",
    "        # Create topics\n",
    "        writer.create_topic(rosbag2_py.TopicMetadata(name='/camera/color/image_raw', type='sensor_msgs/msg/Image', serialization_format='cdr'))\n",
    "        writer.create_topic(rosbag2_py.TopicMetadata(name='/scan', type='sensor_msgs/msg/LaserScan', serialization_format='cdr'))\n",
    "        writer.create_topic(rosbag2_py.TopicMetadata(name='/odom', type='nav_msgs/msg/Odometry', serialization_format='cdr'))\n",
    "        writer.create_topic(rosbag2_py.TopicMetadata(name='/goal_odom', type='nav_msgs/msg/Odometry', serialization_format='cdr'))\n",
    "        writer.create_topic(rosbag2_py.TopicMetadata(name='/tf', type='tf2_msgs/msg/TFMessage', serialization_format='cdr'))\n",
    "        writer.create_topic(rosbag2_py.TopicMetadata(name='/tf_static', type='tf2_msgs/msg/TFMessage', serialization_format='cdr', offered_qos_profiles=qos_profile_tf_static))\n",
    "        \n",
    "\n",
    "        # Write aligned data back to the bag\n",
    "        for img, laser, odom, velocity, timestamp, goal_odom in data:\n",
    "            # Convert the image back to a ROS Image message\n",
    "            img_msg = self.bridge.cv2_to_imgmsg(img, \"bgr8\")\n",
    "            img_msg.header.stamp = rclpy.time.Time(seconds=timestamp * 1e-9).to_msg()\n",
    "\n",
    "            # Create LaserScan message\n",
    "            laser_msg = deserialize_message(laser[1], LaserScan)\n",
    "            laser_msg.header.stamp = rclpy.time.Time(seconds=timestamp * 1e-9).to_msg()\n",
    "\n",
    "            # Create Odometry message\n",
    "            odom_msg = deserialize_message(odom[1], Odometry)\n",
    "            odom_msg.header.stamp = rclpy.time.Time(seconds=timestamp * 1e-9).to_msg()\n",
    "            \n",
    "            # Create Goal Odometry message\n",
    "            goal_odom_msg = deserialize_message(goal_odom[1], Odometry)\n",
    "            goal_odom_msg.header.stamp = rclpy.time.Time(seconds=timestamp * 1e-9).to_msg()\n",
    "\n",
    "            # Write messages to the new bag file\n",
    "            serialized_img = rclpy.serialization.serialize_message(img_msg)\n",
    "            writer.write('/camera/color/image_raw', serialized_img, timestamp)\n",
    "            serialized_laser = rclpy.serialization.serialize_message(laser_msg)\n",
    "            writer.write('/scan', serialized_laser, timestamp)\n",
    "            serialized_odom = rclpy.serialization.serialize_message(odom_msg)\n",
    "            writer.write('/odom', serialized_odom, timestamp)\n",
    "            serialized_goal_odom = rclpy.serialization.serialize_message(goal_odom_msg)\n",
    "            writer.write('/goal_odom', serialized_goal_odom, timestamp)\n",
    "        \n",
    "        # Write tf and tf_static messages to the new bag file\n",
    "        for tf_msg, tf_timestamp in self.tf_messages:\n",
    "            writer.write('/tf', tf_msg, tf_timestamp)\n",
    "        for tf_static_msg, tf_static_timestamp in self.tf_static_messages:\n",
    "            writer.write('/tf_static', tf_static_msg, tf_static_timestamp)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1728343229.516598779] [rosbag2_storage]: Opened database '/home/nigitha/corr1/corr1_0.db3' for READ_ONLY.\n"
     ]
    }
   ],
   "source": [
    "bag_file = \"/home/nigitha/corr1\"  # Replace with your actual bag file path\n",
    "output_dir = \"/home/nigitha/ros2_ws_rnd/src/dataset/corr1\"  # Replace with your output directory path\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "dataset_processor = ImitationLearningDataset(bag_file, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning data\n"
     ]
    }
   ],
   "source": [
    "dataset_processor.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving as pickle files\n"
     ]
    }
   ],
   "source": [
    "dataset_processor.save_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from geometry_msgs.msg import TransformStamped\n",
    "\n",
    "# msg.transforms is a list of TransformStamped messages\n",
    "for msg,_ in dataset_processor.tf_messages:\n",
    "    msg = deserialize_message(msg, TFMessage)\n",
    "    for transform in msg.transforms:\n",
    "        # Check if the transform is from odom to base_link\n",
    "        if transform.child_frame_id == 'odom' and transform.header.frame_id == 'base_link':\n",
    "            # Extract translation and rotation\n",
    "            translation = transform.transform.translation\n",
    "            rotation = transform.transform.rotation\n",
    "            \n",
    "            # Convert quaternion to Euler angles (optional)\n",
    "            euler = euler_from_quaternion([rotation.x, rotation.y, rotation.z, rotation.w])\n",
    "            yaw = euler[2]  # Yaw angle\n",
    "\n",
    "            print(f\"Translation: (x: {translation.x}, y: {translation.y}, z: {translation.z})\")\n",
    "            print(f\"Rotation (quaternion): (x: {rotation.x}, y: {rotation.y}, z: {rotation.z}, w: {rotation.w})\")\n",
    "            print(f\"Yaw (radians): {yaw}\")\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
