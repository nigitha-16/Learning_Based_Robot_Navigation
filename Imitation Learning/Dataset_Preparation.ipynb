{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d87b7592-cb27-4889-b3dd-0ee694de098b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 01:59:45.121300: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-31 01:59:45.139288: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-31 01:59:45.144741: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-31 01:59:45.158665: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-31 01:59:46.521728: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib64/python3.9/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "import os\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import transforms3d\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4015b9a6-1a59-47b3-9641-3a370a2ba3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r\"/work/nselva2s/rnd/robile_data_corr1\"\n",
    "use_images = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb1fd70-af83-49c7-8976-efb8258f8b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading images\n",
      "loaded images\n",
      "loaded data\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "def load_data(input_dir, load_images=False):\n",
    "    # Define paths to your pickle files\n",
    "    image_file = os.path.join(input_dir, 'images.h5')\n",
    "    laser_file = os.path.join(input_dir, 'lasers.pkl')\n",
    "    odom_file = os.path.join(input_dir, 'odoms.pkl')\n",
    "    goal_odom_file = os.path.join(input_dir, 'goal_odoms.pkl')\n",
    "    velocity_file = os.path.join(input_dir, 'velocities.pkl')\n",
    "    tf_file = os.path.join(input_dir, 'tfs.pkl')\n",
    "    \n",
    "    # Load the pickle files\n",
    "    with open(laser_file, 'rb') as f:\n",
    "        lasers_raw = pickle.load(f)\n",
    "        lasers = []\n",
    "        for laser in lasers_raw:\n",
    "            lasers.append([100.0 if math.isnan(x) or math.isinf(x) else x for x in laser])\n",
    "    with open(odom_file, 'rb') as f:\n",
    "        current_poses = pickle.load(f)\n",
    "    with open(goal_odom_file, 'rb') as f:\n",
    "        goal_poses = pickle.load(f)\n",
    "    with open(velocity_file, 'rb') as f:\n",
    "        velocities = pickle.load(f)\n",
    "    # Split velocities into linear and angular components\n",
    "    linear_velocities = np.array(velocities)[:, :2]  # Linear velocity (x, y)\n",
    "    angular_velocities = np.array(velocities)[:, 2]  # Angular velocity (z)\n",
    "    with open(tf_file, 'rb') as f:\n",
    "        tfs = pickle.load(f)\n",
    "    if load_images:\n",
    "        print('loading images')\n",
    "        with h5py.File(image_file, 'r') as f:\n",
    "            image_keys = list(f.keys())\n",
    "            images = [Image.fromarray(f[key][:]) for key in image_keys]\n",
    "        print('loaded images')\n",
    "    else:\n",
    "        images = [None]*len(lasers)\n",
    "\n",
    "    combined_data = list(zip(images, lasers, current_poses, goal_poses, linear_velocities, angular_velocities, tfs))\n",
    "    return  combined_data\n",
    "\n",
    "\n",
    "\n",
    "data = load_data(os.path.join(input_dir, 'downsampled_data'), load_images=use_images)\n",
    "print('loaded data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca3ce6e3-e35e-4d82-8247-62dec5cd85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transforms3d\n",
    "\n",
    "# Function to invert a transformation (translation + rotation)\n",
    "def invert_transform(translation, rotation):\n",
    "    # Convert the quaternion to a rotation matrix (3x3)\n",
    "    rotation_matrix = transforms3d.quaternions.quat2mat([rotation[3], rotation[0], rotation[1], rotation[2]])[:3, :3]\n",
    "    # Invert the rotation matrix (transpose of a rotation matrix is its inverse)\n",
    "    rotation_matrix_inv = np.transpose(rotation_matrix)\n",
    "    \n",
    "    # Invert the translation (apply the inverse rotation to the negative translation)\n",
    "    translation_inv = -np.dot(rotation_matrix_inv, [translation[0], translation[1], translation[2]])\n",
    "    \n",
    "    # Create the inverse quaternion (negate the vector part, keep the scalar part the same)\n",
    "    rotation_inv = transforms3d.quaternions.qinverse([rotation[3], rotation[0], rotation[1], rotation[2]])\n",
    "    return translation_inv, rotation_inv\n",
    "\n",
    "# Function to apply the transformation (translation + rotation) to a point\n",
    "def transform_point(translation, rotation, point):\n",
    "    # Convert the point to a homogeneous vector (x, y, z, 1)\n",
    "    point_homogeneous = np.array([point[0], point[1], point[2], 1.0])\n",
    "    \n",
    "    # Create the translation matrix (4x4)\n",
    "    translation_matrix = np.identity(4)\n",
    "    translation_matrix[0, 3] = translation[0]\n",
    "    translation_matrix[1, 3] = translation[1]\n",
    "    translation_matrix[2, 3] = translation[2]\n",
    "    # Create the transformation matrix from translation and rotation\n",
    "    rotation_matrix = np.identity(4)\n",
    "    rotation_matrix[:3, :3] = transforms3d.quaternions.quat2mat(rotation)[:3, :3]\n",
    "    # Combine translation and rotation into a single transformation matrix\n",
    "    transformation_matrix = np.dot(translation_matrix, rotation_matrix)\n",
    "    # Apply the transformation to the point\n",
    "    transformed_point = np.dot(transformation_matrix, point_homogeneous)\n",
    "    \n",
    "    \n",
    "    # Return the transformed point (x, y, z)\n",
    "    return transformed_point[:3]\n",
    "\n",
    "# Function to transform a point from odom to base_link frame\n",
    "def transform_pose_to_base_link(translation, rotation, point_in_odom):\n",
    "    # Get the inverse of the transformation\n",
    "    translation_inv, rotation_inv = invert_transform(translation, rotation)\n",
    "    \n",
    "    # Convert the point from odom to base_link using the inverted transformation\n",
    "    point_in_base_link = transform_point(translation_inv, rotation_inv, point_in_odom)\n",
    "    \n",
    "    return point_in_base_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d2278af-4de2-4ef7-b99d-0ca2c3b74c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasers = []\n",
    "current_poses = []\n",
    "goal_poses = []\n",
    "linear_velocities = []\n",
    "angular_velocities = []\n",
    "tfs = []\n",
    "images = []\n",
    "goals = []\n",
    "target_distance = 0.2\n",
    "forward_goal_thresh = 1.4\n",
    "sampling_probability = 0.4\n",
    "\n",
    "for i, (_, _, _, goal_pose1, _, _, _) in enumerate(data):\n",
    "    for j, (image2, laser2, current_pose2, _, linear_velocity2, angular_velocity2, tf2) in enumerate(data[i:]):   \n",
    "        if random.random() > sampling_probability:\n",
    "            continue\n",
    "        distance = np.sqrt((goal_pose1[0] - current_pose2[0]) ** 2 + (goal_pose1[1] - current_pose2[1]) ** 2)\n",
    "        if distance >= target_distance:\n",
    "            goal_baselink = transform_pose_to_base_link(tf2[0], tf2[1], goal_pose1)\n",
    "            goal_distance = distance\n",
    "            goal_angle = math.atan2(goal_baselink[1],goal_baselink[0])\n",
    "            if abs(goal_angle) < forward_goal_thresh:\n",
    "                goals.append([goal_distance, goal_angle])\n",
    "                lasers.append(laser2)\n",
    "                if use_images:\n",
    "                    images.append(image2)\n",
    "                current_poses.append(current_pose2)\n",
    "                goal_poses.append(goal_pose1)\n",
    "                linear_velocities.append(linear_velocity2)\n",
    "                angular_velocities.append(angular_velocity2)\n",
    "                tfs.append(tf2)\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ea0ff7-04b2-4946-9476-cd16517ee133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get motion commands\n"
     ]
    }
   ],
   "source": [
    "print('get motion commands')\n",
    "motion_commands = np.concatenate([np.expand_dims(np.array(linear_velocities)[:,0], axis=1), np.expand_dims(np.array(linear_velocities)[:,1], axis=1), np.expand_dims(angular_velocities, axis=1)], axis=1)  # Shape: (1000, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b73accd-027d-447b-837d-d72653a1c787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227025"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lasers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59534b1f-30c7-4f3b-a676-afa9df677cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_file = os.path.join(input_dir, 'tfrecords/corr1_withImages_downsampled.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dcaed77-1c50-4727-a1c6-3ca4254069b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 02:00:49.576357: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def serialize_metadata(dataset_length):\n",
    "    feature = {\n",
    "        'metadata': tf.train.Feature(bytes_list=tf.train.BytesList(value=[b\"metadata\"])),\n",
    "        'length': tf.train.Feature(int64_list=tf.train.Int64List(value=[dataset_length]))\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "    \n",
    "def serialize_example(laser, goal, motion_command, image=None):\n",
    "    if image is not None:\n",
    "        feature = {\n",
    "            'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.serialize_tensor(image).numpy()])),\n",
    "            # 'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(image).numpy()])),\n",
    "            'laser': tf.train.Feature(float_list=tf.train.FloatList(value=laser)),\n",
    "            'goal': tf.train.Feature(float_list=tf.train.FloatList(value=goal)),\n",
    "            'motion_command': tf.train.Feature(float_list=tf.train.FloatList(value=motion_command))\n",
    "        }\n",
    "    else:\n",
    "        feature = {\n",
    "            'laser': tf.train.Feature(float_list=tf.train.FloatList(value=laser)),\n",
    "            'goal': tf.train.Feature(float_list=tf.train.FloatList(value=goal)),\n",
    "            'motion_command': tf.train.Feature(float_list=tf.train.FloatList(value=motion_command))\n",
    "        }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "def write_tfrecord(file_path, lasers, goal, motion_commands, images):\n",
    "    dataset_length = len(lasers)\n",
    "    # Create a list of indices and shuffle it\n",
    "    indices = list(range(dataset_length))\n",
    "    random.shuffle(indices)\n",
    "    with tf.io.TFRecordWriter(file_path) as writer:\n",
    "        writer.write(serialize_metadata(dataset_length))\n",
    "        for i in indices:\n",
    "            if len(images) !=0:\n",
    "                example = serialize_example(\n",
    "                    lasers[i], goal[i], motion_commands[i], images[i]\n",
    "                )\n",
    "            else:\n",
    "                 example = serialize_example(\n",
    "                lasers[i], goal[i], motion_commands[i]\n",
    "            )\n",
    "            writer.write(example)\n",
    "\n",
    "write_tfrecord(tf_file, lasers, goals, motion_commands, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab18cde-3390-41a4-802c-5d4dc69e4725",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_lasers = []\n",
    "sampled_images = []\n",
    "sampled_goals = []\n",
    "sampled_motion_commands = []\n",
    "num_bins = 10  # Number of bins\n",
    "samples_per_bin = 29000  # Number of samples per bin\n",
    "\n",
    "x = np.array(goal)[:,1]\n",
    "# Create bins based on 'x' values\n",
    "bins = np.linspace(x.min(), x.max(), num_bins + 1)  # Create bin edges\n",
    "\n",
    "# Digitize the 'x' values to assign them to bins\n",
    "bin_indices = np.digitize(x, bins)\n",
    "\n",
    "\n",
    "\n",
    "# Sample uniformly from each bin\n",
    "for i in range(1, num_bins + 1):\n",
    "    # Get indices of data points in the current bin\n",
    "    indices_in_bin = np.where(bin_indices == i)[0]\n",
    "    \n",
    "    if len(indices_in_bin) > 0:\n",
    "        # Randomly sample from the bin\n",
    "        sampled_indices = np.random.choice(indices_in_bin, size=min(samples_per_bin, len(indices_in_bin)), replace=True)\n",
    "        sampled_lasers.extend(np.array(lasers)[sampled_indices])\n",
    "        if use_images:\n",
    "            sampled_images.extend(np.array(images)[sampled_indices])\n",
    "        sampled_goals.extend(np.array(goal)[sampled_indices])\n",
    "        sampled_motion_commands.extend(np.array(motion_commands)[sampled_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a0ddbbf-fe16-495c-a09e-041440350e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05798887208369319\n"
     ]
    }
   ],
   "source": [
    "print(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44fdfbd9-bae3-4788-bd26-fbd662fbc72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c721c8f-95f5-433f-9df3-ecef0f7ec209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6013 (pid 286342), started 0:00:10 ago. (Use '!kill 286342' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c9cd71ed02cc93c0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c9cd71ed02cc93c0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6013;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b164abee-f3f9-4488-9297-e0055e29e159",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 84794"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
