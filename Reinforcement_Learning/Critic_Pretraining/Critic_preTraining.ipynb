{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae89b9bc-4780-4557-8cc7-068b58145035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 00:56:07.977833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-22 00:56:07.996068: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-22 00:56:08.001470: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-22 00:56:08.015436: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-22 00:56:09.492155: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib64/python3.9/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, Model\n",
    "import random\n",
    "from collections import deque\n",
    "import os\n",
    "import tensorflow.summary as tf_summary\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import random\n",
    "import yaml\n",
    "import argparse\n",
    "import transforms3d\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU, Add, Flatten, Dense, concatenate, Rescaling, Normalization, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras import Model, Input, regularizers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd084d82-8b94-4e01-a4e5-35936e6e7f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetLoader:\n",
    "    def __init__(self, tfrecord_file, image_shape=[224, 224, 3], lasers_shape=513, goal_shape=2, motion_command_shape=3, reward_shape = 1):\n",
    "        self.tfrecord_file = tfrecord_file\n",
    "        self.image_shape = image_shape\n",
    "        self.lasers_shape = lasers_shape\n",
    "        self.goal_shape = goal_shape\n",
    "        self.motion_command_shape = motion_command_shape\n",
    "        self.reward_shape = reward_shape\n",
    "        self.dataset_length = self._get_dataset_length()\n",
    "        print(self.dataset_length)\n",
    "\n",
    "    def _parse_with_lasers_function(self,proto):\n",
    "        features = {\n",
    "            'laser': tf.io.FixedLenFeature([self.lasers_shape], tf.float32),\n",
    "            'goal': tf.io.FixedLenFeature([self.goal_shape], tf.float32),\n",
    "            'next_laser': tf.io.FixedLenFeature([self.lasers_shape], tf.float32),\n",
    "            'next_goal': tf.io.FixedLenFeature([self.goal_shape], tf.float32),\n",
    "            'motion_command': tf.io.FixedLenFeature([self.motion_command_shape], tf.float32),\n",
    "            'reward': tf.io.FixedLenFeature([self.reward_shape], tf.float32),\n",
    "        }\n",
    "        parsed_features = tf.io.parse_single_example(proto, features)\n",
    "        return  (parsed_features['laser'], parsed_features['goal'], parsed_features['motion_command'], parsed_features['reward'],\n",
    "                 parsed_features['next_laser'], parsed_features['next_goal'])\n",
    "\n",
    "    def _get_dataset_length(self):\n",
    "        dataset = tf.data.TFRecordDataset(self.tfrecord_file)\n",
    "        metadata_features = {\n",
    "            'metadata': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "            'length': tf.io.FixedLenFeature([], tf.int64, default_value=-1)\n",
    "        }\n",
    "        \n",
    "        for record in dataset.take(1):\n",
    "            parsed_features = tf.io.parse_single_example(record, metadata_features)\n",
    "            dataset_length = parsed_features['length'].numpy()\n",
    "            return dataset_length\n",
    "        \n",
    "        print(\"Metadata not found. Setting length to None.\")\n",
    "        return None\n",
    "\n",
    "    def load_dataset(self):\n",
    "        dataset = tf.data.TFRecordDataset(self.tfrecord_file)\n",
    "        dataset = dataset.skip(1).map(self._parse_with_lasers_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    def split_dataset(self, dataset, train_size=0.7, val_size=0.2):\n",
    "        num_elements = self.dataset_length\n",
    "        if num_elements is None:\n",
    "            raise ValueError(\"Dataset length is not set. Ensure the metadata is properly included in the TFRecord.\")\n",
    "        \n",
    "        train_end = int(train_size * num_elements)\n",
    "        val_end = int((train_size + val_size) * num_elements)\n",
    "        \n",
    "        train_dataset = dataset.take(train_end)\n",
    "        val_dataset = dataset.skip(train_end).take(val_end - train_end)\n",
    "        test_dataset = dataset.skip(val_end).take(num_elements - val_end)\n",
    "     \n",
    "        \n",
    "        return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "    def get_prepared_datasets(self, train_size=0.7, val_size=0.2):\n",
    "        dataset = self.load_dataset()\n",
    "        \n",
    "        train_dataset, val_dataset, test_dataset = self.split_dataset(dataset, train_size, val_size)\n",
    "        \n",
    "        return train_dataset, val_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e028e4f-c3fb-43e9-ab45-60e00e16c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Actor Network (Policy)\n",
    "class Actor(tf.keras.Model):\n",
    "    def __init__(self, model_path):\n",
    "        super(Actor, self).__init__()\n",
    "        self.model = tf.keras.models.load_model(model_path, compile=False)\n",
    "\n",
    "    def call(self, laser, goal):\n",
    "        return self.model([laser, goal])\n",
    "\n",
    "# Define the Critic Network (Q-value function)\n",
    "class Critic(tf.keras.Model):\n",
    "    def __init__(self, laser_shape, goal_shape, motion_command_shape, reward_shape):\n",
    "        super(Critic, self).__init__()\n",
    "        self.laser_shape = laser_shape\n",
    "        self.goal_shape = goal_shape\n",
    "        self.motion_command_shape = motion_command_shape\n",
    "        self.reward_shape = reward_shape\n",
    "\n",
    "        # Define normalization layers\n",
    "        self.laser_normalization = Normalization()\n",
    "        self.goal_normalization = Normalization()\n",
    "        self.reward_normalization = Normalization()\n",
    "\n",
    "        # Initialize the model\n",
    "        self.model = self._create_model()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def _create_model(self):\n",
    "        \"\"\"\n",
    "        Creates a TensorFlow model for processing laser scans, goals, motion commands, and predicting rewards.\n",
    "        \n",
    "        :return: tf.keras.Model\n",
    "        \"\"\"\n",
    "        # Define inputs\n",
    "        laser_input = Input(shape=(self.laser_shape,), name='laser_input')\n",
    "        goal_input = Input(shape=(self.goal_shape,), name='goal_input')\n",
    "        motion_command_input = Input(shape=(self.motion_command_shape,), name='motion_command_input')\n",
    "    \n",
    "        # Optional normalization\n",
    "        laser_normalized = self.laser_normalization(laser_input)\n",
    "        goal_normalized = self.goal_normalization(goal_input)\n",
    "        motion_command_normalized = self.reward_normalization(motion_command_input)\n",
    "    \n",
    "        # Laser processing\n",
    "        laser_hidden = Dense(64, kernel_initializer=HeNormal(), kernel_regularizer=regularizers.l2(1e-4))(laser_normalized)\n",
    "        laser_hidden = BatchNormalization()(laser_hidden)\n",
    "        laser_hidden = LeakyReLU()(laser_hidden)\n",
    "        laser_hidden = Dropout(0.2)(laser_hidden)\n",
    "        laser_hidden = Dense(32, kernel_initializer=HeNormal(), kernel_regularizer=regularizers.l2(1e-4))(laser_hidden)\n",
    "        laser_hidden = BatchNormalization()(laser_hidden)\n",
    "        laser_hidden = LeakyReLU()(laser_hidden)\n",
    "\n",
    "         # Goal processing\n",
    "        goal_hidden = Dense(16, kernel_initializer=HeNormal(), kernel_regularizer=regularizers.l2(1e-4))(goal_normalized)\n",
    "        goal_hidden = BatchNormalization()(goal_hidden)\n",
    "        goal_hidden = LeakyReLU()(goal_hidden)\n",
    "        goal_hidden = Dropout(0.2)(goal_hidden)\n",
    "        goal_hidden = Dense(32, kernel_initializer=HeNormal(), kernel_regularizer=regularizers.l2(1e-4))(goal_hidden)\n",
    "        goal_hidden = BatchNormalization()(goal_hidden)\n",
    "        goal_hidden = LeakyReLU()(goal_hidden)\n",
    "    \n",
    "        # Motion command processing\n",
    "        motion_command_hidden = Dense(8, kernel_initializer=HeNormal(), kernel_regularizer=regularizers.l2(1e-4))(motion_command_normalized)\n",
    "        motion_command_hidden = BatchNormalization()(motion_command_hidden)\n",
    "        motion_command_hidden = LeakyReLU()(motion_command_hidden)\n",
    "        motion_command_hidden = Dropout(0.2)(motion_command_hidden)\n",
    "        motion_command_hidden = Dense(32, kernel_initializer=HeNormal(), kernel_regularizer=regularizers.l2(1e-4))(motion_command_hidden)\n",
    "        motion_command_hidden = BatchNormalization()(motion_command_hidden)\n",
    "        motion_command_hidden = LeakyReLU()(motion_command_hidden)\n",
    "    \n",
    "        # Concatenate processed features\n",
    "        concatenated = concatenate([laser_hidden, goal_hidden, motion_command_hidden])\n",
    "    \n",
    "        # Fully connected layers after concatenation\n",
    "        hidden = Dense(32, kernel_initializer=HeNormal(), kernel_regularizer=regularizers.l2(1e-4))(concatenated)\n",
    "        hidden = BatchNormalization()(hidden)\n",
    "        hidden = LeakyReLU()(hidden)\n",
    "        hidden = Dropout(0.2)(hidden)\n",
    "        hidden = Dense(16, kernel_initializer=HeNormal(), kernel_regularizer=regularizers.l2(1e-4))(hidden)\n",
    "        hidden = BatchNormalization()(hidden)\n",
    "        hidden = LeakyReLU()(hidden)\n",
    "        hidden = Dropout(0.2)(hidden)\n",
    "    \n",
    "        # Output layer for reward\n",
    "        output = Dense(1, activation='linear', name='reward_output')(hidden)\n",
    "    \n",
    "        # Create and return the model\n",
    "        model = Model(inputs=[laser_input, goal_input, motion_command_input], outputs=output)\n",
    "        return model\n",
    "\n",
    "    def call(self, laser, goal, action):\n",
    "        return self.model([laser, goal, action])\n",
    "\n",
    "\n",
    "# DDPG Agent\n",
    "class DDPGAgent:\n",
    "    def __init__(self, laser_shape, goal_shape, motion_command_shape, reward_shape, pretrained_actor_model_path, gamma=0.8, tau=0.005, lr=1e-3):\n",
    "        self.actor = Actor(pretrained_actor_model_path)\n",
    "        self.critic = Critic(laser_shape, goal_shape, motion_command_shape, reward_shape)\n",
    "        self.target_actor = Actor(pretrained_actor_model_path)\n",
    "        self.target_critic = Critic(laser_shape, goal_shape, motion_command_shape, reward_shape)\n",
    "\n",
    "        # Initialize target networks to be the same as the original networks\n",
    "        self.target_actor.set_weights(self.actor.get_weights())\n",
    "        self.target_critic.set_weights(self.critic.get_weights())\n",
    "\n",
    "        self.critic_optimizer = optimizers.Adam(lr)\n",
    "        \n",
    "        self.gamma = gamma  # Discount factor for future rewards\n",
    "        self.tau = tau  # Target network update rate      \n",
    "\n",
    "            \n",
    "    def update(self, train_batch):\n",
    "\n",
    "        # Sample a batch of transitions from the replay buffer\n",
    "        state_laser, state_goal, action, reward, next_state_laser, next_state_goal = train_batch\n",
    "        state = [np.array(state_laser), np.array(state_goal)]\n",
    "        action = np.array(action)\n",
    "        reward = np.array(reward)\n",
    "        next_state = [np.array(next_state_laser), np.array(next_state_goal)]\n",
    "        done = 0\n",
    "        \n",
    "        target_action = self.target_actor(next_state[0], next_state[1])\n",
    "        target_q_value = self.target_critic(next_state[0], next_state[1], target_action)\n",
    "        target = reward + (1 - done) * self.gamma * target_q_value\n",
    "\n",
    "        # Update Critic\n",
    "        with tf.GradientTape() as tape:        \n",
    "            current_q_value = self.critic(state[0], state[1], action)\n",
    "            critic_loss = tf.reduce_mean(tf.square(current_q_value - target))\n",
    "\n",
    "        critic_grads = tape.gradient(critic_loss, self.critic.trainable_variables)\n",
    "        \n",
    "        self.critic_optimizer.apply_gradients(zip(critic_grads, self.critic.trainable_variables))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        return critic_loss.numpy()\n",
    "\n",
    "    def soft_update(self, source, target):\n",
    "        source_weights = source.get_weights()\n",
    "        target_weights = target.get_weights()\n",
    "\n",
    "        new_weights = []\n",
    "        for source_w, target_w in zip(source_weights, target_weights):\n",
    "            new_weights.append(self.tau * source_w + (1.0 - self.tau) * target_w)\n",
    "\n",
    "        target.set_weights(new_weights)\n",
    "\n",
    "    def validate(self, val_dataset, val_steps, batch_size):\n",
    "        \n",
    "        val_dataset_= val_dataset.shuffle(buffer_size=1000).batch(batch_size)\n",
    "        val_dataset_ = val_dataset_.prefetch(tf.data.AUTOTUNE)\n",
    "        val_critic_loss=[]\n",
    "        for step in range(val_steps):\n",
    "            val_batch = next(iter(val_dataset_))\n",
    "            print(step)\n",
    "            state_laser, state_goal, action, reward, next_state_laser, next_state_goal = val_batch\n",
    "            state = [np.array(state_laser), np.array(state_goal)]\n",
    "            action = np.array(action)\n",
    "            reward = np.array(reward)\n",
    "            next_state = [np.array(next_state_laser), np.array(next_state_goal)]\n",
    "            done = 0\n",
    "            target_action = self.target_actor(next_state[0], next_state[1])\n",
    "            target_q_value = self.target_critic(next_state[0], next_state[1], target_action)\n",
    "            target = reward + (1 - done) * self.gamma * target_q_value\n",
    "    \n",
    "            current_q_value = self.critic(state[0], state[1], action)\n",
    "            critic_loss = tf.reduce_mean(tf.square(current_q_value - target))\n",
    "            val_critic_loss.append(critic_loss)\n",
    "            print('v-end')\n",
    "            \n",
    "        val_critic_loss = sum(val_critic_loss)/len(val_critic_loss)\n",
    "        return val_critic_loss.numpy()\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed134bf0-262d-4ddb-a35e-b04906936e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420699\n",
      "train 0\n",
      "t-end\n",
      "train 1\n",
      "t-end\n",
      "train 2\n",
      "t-end\n",
      "train 3\n",
      "t-end\n",
      "train 4\n",
      "t-end\n",
      "epoch complete\n",
      "model saved\n",
      "validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 23:41:50.582191: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:357: Filling up shuffle buffer (this may take a while): 1 of 1000\n",
      "2025-01-21 23:41:50.712206: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m writer \u001b[38;5;241m=\u001b[39m tf_summary\u001b[38;5;241m.\u001b[39mcreate_file_writer(log_dir)\n\u001b[1;32m     75\u001b[0m agent \u001b[38;5;241m=\u001b[39m DDPGAgent(laser_shape, goal_shape, motion_command_shape, reward_shape, pretrained_actor_model_path\u001b[38;5;241m=\u001b[39mpretrained_actor_model_path) \n\u001b[0;32m---> 76\u001b[0m \u001b[43mtrain_critic\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m test_critic_loss \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mvalidate(test_dataset, test_steps)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m writer\u001b[38;5;241m.\u001b[39mas_default():\n",
      "Cell \u001b[0;32mIn[32], line 24\u001b[0m, in \u001b[0;36mtrain_critic\u001b[0;34m(agent, train_dataset, val_dataset, batch_size, model_save_path, epochs, train_steps, val_steps)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel saved\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidating\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m val_critic_loss \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Log metrics\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m writer\u001b[38;5;241m.\u001b[39mas_default():\n",
      "Cell \u001b[0;32mIn[31], line 158\u001b[0m, in \u001b[0;36mDDPGAgent.validate\u001b[0;34m(self, val_dataset, val_steps, batch_size)\u001b[0m\n\u001b[1;32m    156\u001b[0m val_critic_loss\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(val_steps):\n\u001b[0;32m--> 158\u001b[0m     val_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_dataset_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mprint\u001b[39m(step)\n\u001b[1;32m    160\u001b[0m     state_laser, state_goal, action, reward, next_state_laser, next_state_goal \u001b[38;5;241m=\u001b[39m val_batch\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:826\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    825\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:776\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 776\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3081\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3080\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3081\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3082\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIteratorGetNext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3083\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3084\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3085\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "def train_critic(agent, train_dataset, val_dataset, batch_size, model_save_path, epochs=100, train_steps=1000, val_steps=200):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_dataset_= train_dataset.shuffle(buffer_size=10000).batch(batch_size)\n",
    "        train_dataset_ = train_dataset_.prefetch(tf.data.AUTOTUNE)\n",
    "        for step in range(train_steps):\n",
    "            train_batch = next(iter(train_dataset_))\n",
    "            print('train',step)\n",
    "            critic_loss = agent.update(train_batch)            \n",
    "            if step%50==0:\n",
    "                agent.soft_update(agent.critic, agent.target_critic)\n",
    "\n",
    "            if epoch%5==0:            \n",
    "                with writer.as_default():\n",
    "                    tf_summary.scalar(f\"Episode_{epoch} Critic Loss\", critic_loss, step=step)\n",
    "            print('t-end')\n",
    "        print('epoch complete')\n",
    "        if epoch%50==0:\n",
    "            model_save_path = os.path.join(model_save_path, f\"{model_name}_model_episode_{epoch+1}.keras\")\n",
    "            agent.critic.save(model_save_path)\n",
    "            print('model saved')\n",
    "        print('validating')\n",
    "        val_critic_loss = agent.validate(val_dataset, val_steps, batch_size)\n",
    "        \n",
    "        # Log metrics\n",
    "        with writer.as_default():\n",
    "            tf_summary.scalar(\"Critic Loss\", critic_loss, step=epoch)\n",
    "            tf_summary.scalar(\"Validation Critic Loss\", val_critic_loss, step=epoch)\n",
    "\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "# Load the configuration\n",
    "config = load_config('/work/nselva2s/rnd/repo/src/Reinforcement_Learning/Critic_Pretraining/config_rl_critic_laser.yaml')\n",
    "\n",
    "root_dir = config['root_dir']\n",
    "tf_file = os.path.join(root_dir, config['tfrecord_file'])\n",
    "\n",
    "log_dir = config['log_dir'] +datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = os.path.join(root_dir, log_dir)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "model_save_path = os.path.join(root_dir, config['model_save_path'])\n",
    "model_name = config['model_name']\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "pretrained_actor_model_path = config['pretrained_actor_model_path']\n",
    "pretrained_actor_model_path = os.path.join(root_dir, pretrained_actor_model_path)\n",
    "\n",
    "# epochs=config['epochs']\n",
    "# train_steps = config['train_steps']\n",
    "# batch_size = config['batch_size']\n",
    "# val_steps = config['val_steps']\n",
    "# test_steps = config['test_steps']\n",
    "\n",
    "epochs=10\n",
    "train_steps = 5\n",
    "batch_size = 128\n",
    "val_steps = 10\n",
    "test_steps = 50\n",
    "\n",
    "laser_shape = 513\n",
    "goal_shape = 2\n",
    "motion_command_shape = 3\n",
    "reward_shape = 1\n",
    "\n",
    "loader = DatasetLoader(tf_file)\n",
    "train_dataset, val_dataset, test_dataset = loader.get_prepared_datasets(train_size = config['train_size'], val_size = config['val_size'])\n",
    "\n",
    "writer = tf_summary.create_file_writer(log_dir)\n",
    "\n",
    "agent = DDPGAgent(laser_shape, goal_shape, motion_command_shape, reward_shape, pretrained_actor_model_path=pretrained_actor_model_path) \n",
    "train_critic(agent, train_dataset, val_dataset, batch_size, model_save_path, epochs, train_steps, val_steps)\n",
    "test_critic_loss = agent.validate(test_dataset, test_steps)\n",
    "with writer.as_default():\n",
    "    tf_summary.scalar(\"Test Critic Loss\", test_critic_loss, step=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c7989ca-34f4-4d2c-a1f4-8dc284e59831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "ds = loader.load_dataset()\n",
    "ds = ds.shuffle(buffer_size=10000, reshuffle_each_iteration=False)\n",
    "tr, v, tes = loader.split_dataset(ds, 0.1, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d48233e-343a-471b-a35f-9293892d32b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "jkdak\n",
      "1\n",
      "jkdak\n",
      "2\n",
      "jkdak\n"
     ]
    }
   ],
   "source": [
    "val_dataset_= v.shuffle(buffer_size=1000).batch(batch_size)\n",
    "val_dataset_ = val_dataset_.prefetch(tf.data.AUTOTUNE)\n",
    "val_critic_loss=[]\n",
    "for step in range(3):\n",
    "    print(step)\n",
    "    val_batch = next(iter(val_dataset_))\n",
    "    print('jkdak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc2ca290-fed2-4154-a14c-27bb46d9a4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 00:18:07.604424: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:478: Filling up shuffle buffer (this may take a while): 24574 of 100000\n",
      "2025-01-22 00:18:17.364178: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "val_dataset_= v.shuffle(buffer_size=100000).batch(batch_size)\n",
    "val_dataset_ = val_dataset_.prefetch(tf.data.AUTOTUNE)\n",
    "val_critic_loss=[]\n",
    "c = 0\n",
    "for batch in val_dataset_:\n",
    "    print(c)\n",
    "    c=c+1\n",
    "    if c>5:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a1b6d5c-c075-4ffd-b1ea-148ba271ce4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420699\n"
     ]
    }
   ],
   "source": [
    "import ddpg_critic_pretraining_agent \n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "    \n",
    "# Load the configuration\n",
    "config = load_config('/work/nselva2s/rnd/repo/src/Reinforcement_Learning/Critic_Pretraining/config_rl_critic_laser.yaml')\n",
    "\n",
    "root_dir = config['root_dir']\n",
    "tf_file = os.path.join(root_dir, config['tfrecord_file'])\n",
    "loader = DatasetLoader(tf_file)\n",
    "train_dataset, val_dataset, test_dataset = loader.get_prepared_datasets(train_size = config['train_size'], val_size = config['val_size'])\n",
    "model = tf.keras.models.load_model('/work/nselva2s/rnd/ReinforcementLearning_models/pretrained_critic_laser_corr07112024_a_model_episode_1.keras',compile=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a812a7ae-ff5e-4a90-b30b-dc3593b257ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 01:44:39.922954: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:37: Filling up shuffle buffer (this may take a while): 1 of 100000\n",
      "2025-01-22 01:44:46.449376: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer \"functional\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor: shape=(128, 513), dtype=float32, numpy=\narray([[1.334, 1.334, 1.335, ..., 2.193, 2.193, 2.196],\n       [1.652, 1.648, 1.637, ..., 2.379, 2.363, 2.355],\n       [4.525, 4.523, 4.519, ..., 1.234, 1.231, 1.229],\n       ...,\n       [1.099, 1.09 , 1.089, ..., 2.435, 2.436, 2.435],\n       [1.402, 1.402, 1.402, ..., 0.799, 0.797, 0.797],\n       [0.595, 0.593, 0.593, ..., 2.787, 2.787, 2.784]], dtype=float32)>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_batch \u001b[38;5;129;01min\u001b[39;00m test_dataset_:\n\u001b[1;32m      4\u001b[0m     state_laser, state_goal, action, reward, next_state_laser, next_state_goal \u001b[38;5;241m=\u001b[39m test_batch\n\u001b[0;32m----> 5\u001b[0m     q_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_laser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_goal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/layers/input_spec.py:160\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_spec):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s),\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but it received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input tensors. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_index, (x, spec) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(inputs, input_spec)):\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Layer \"functional\" expects 3 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor: shape=(128, 513), dtype=float32, numpy=\narray([[1.334, 1.334, 1.335, ..., 2.193, 2.193, 2.196],\n       [1.652, 1.648, 1.637, ..., 2.379, 2.363, 2.355],\n       [4.525, 4.523, 4.519, ..., 1.234, 1.231, 1.229],\n       ...,\n       [1.099, 1.09 , 1.089, ..., 2.435, 2.436, 2.435],\n       [1.402, 1.402, 1.402, ..., 0.799, 0.797, 0.797],\n       [0.595, 0.593, 0.593, ..., 2.787, 2.787, 2.784]], dtype=float32)>]"
     ]
    }
   ],
   "source": [
    "test_dataset_= test_dataset.shuffle(buffer_size=100000).batch(128)\n",
    "test_dataset_ = test_dataset_.prefetch(tf.data.AUTOTUNE)\n",
    "for test_batch in test_dataset_:\n",
    "    state_laser, state_goal, action, reward, next_state_laser, next_state_goal = test_batch\n",
    "    q_pred = model([state_laser, state_goal, action])\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf173c4c-efa4-452c-abe7-1636025fd2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_pred = model([state_laser, state_goal, action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c07ad815-f7d2-4ee6-ae78-a616b6f946c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 1), dtype=float32, numpy=\n",
       "array([[  5.566354  ],\n",
       "       [  6.1339426 ],\n",
       "       [  4.0919085 ],\n",
       "       [  6.962619  ],\n",
       "       [ 20.425295  ],\n",
       "       [ 12.030766  ],\n",
       "       [ 34.029587  ],\n",
       "       [  3.683224  ],\n",
       "       [ 12.870767  ],\n",
       "       [ 16.84511   ],\n",
       "       [  3.7487519 ],\n",
       "       [ 19.663013  ],\n",
       "       [  8.189832  ],\n",
       "       [  5.464986  ],\n",
       "       [ 16.01029   ],\n",
       "       [ 12.051841  ],\n",
       "       [ 14.108821  ],\n",
       "       [  4.1974897 ],\n",
       "       [ 13.011275  ],\n",
       "       [  8.291923  ],\n",
       "       [ 10.486874  ],\n",
       "       [  8.067769  ],\n",
       "       [ 11.515433  ],\n",
       "       [  6.653762  ],\n",
       "       [  5.9220457 ],\n",
       "       [  5.9138546 ],\n",
       "       [ 28.936562  ],\n",
       "       [ 11.216077  ],\n",
       "       [ 20.396439  ],\n",
       "       [ 25.065018  ],\n",
       "       [  4.876897  ],\n",
       "       [ 16.006666  ],\n",
       "       [112.53276   ],\n",
       "       [ 15.004068  ],\n",
       "       [ 18.035015  ],\n",
       "       [130.58313   ],\n",
       "       [  6.818269  ],\n",
       "       [ 10.761857  ],\n",
       "       [ 12.59332   ],\n",
       "       [ 24.407187  ],\n",
       "       [ 15.069953  ],\n",
       "       [  3.9905407 ],\n",
       "       [111.91922   ],\n",
       "       [ 15.276104  ],\n",
       "       [  3.3575852 ],\n",
       "       [107.71471   ],\n",
       "       [ 14.522232  ],\n",
       "       [ -1.0427884 ],\n",
       "       [ 12.072358  ],\n",
       "       [111.91922   ],\n",
       "       [  1.2010642 ],\n",
       "       [ 10.7042265 ],\n",
       "       [117.81549   ],\n",
       "       [  9.605627  ],\n",
       "       [-19.450344  ],\n",
       "       [  7.8324347 ],\n",
       "       [ 11.732696  ],\n",
       "       [ 10.285501  ],\n",
       "       [  2.577863  ],\n",
       "       [  8.712892  ],\n",
       "       [ 17.400473  ],\n",
       "       [ 22.713182  ],\n",
       "       [  7.7714033 ],\n",
       "       [  8.236934  ],\n",
       "       [ 11.693011  ],\n",
       "       [110.30374   ],\n",
       "       [  8.278335  ],\n",
       "       [ 23.33366   ],\n",
       "       [  8.585933  ],\n",
       "       [  3.927457  ],\n",
       "       [  9.275666  ],\n",
       "       [-11.295896  ],\n",
       "       [ 19.032839  ],\n",
       "       [  9.546084  ],\n",
       "       [  9.156736  ],\n",
       "       [ 14.302627  ],\n",
       "       [ 14.450416  ],\n",
       "       [ 13.7811    ],\n",
       "       [ -0.6972626 ],\n",
       "       [119.5235    ],\n",
       "       [ -4.286435  ],\n",
       "       [165.45264   ],\n",
       "       [-18.989542  ],\n",
       "       [ 20.518871  ],\n",
       "       [  7.762767  ],\n",
       "       [ 18.889248  ],\n",
       "       [  5.916976  ],\n",
       "       [ 12.979099  ],\n",
       "       [ 16.358433  ],\n",
       "       [  6.939557  ],\n",
       "       [  7.673091  ],\n",
       "       [115.82231   ],\n",
       "       [ 16.515753  ],\n",
       "       [  7.8252935 ],\n",
       "       [ 13.126333  ],\n",
       "       [  8.571532  ],\n",
       "       [ 15.793445  ],\n",
       "       [  9.233127  ],\n",
       "       [ -5.120885  ],\n",
       "       [  3.4159768 ],\n",
       "       [ -2.3688018 ],\n",
       "       [  7.6114025 ],\n",
       "       [  6.5570135 ],\n",
       "       [  1.1859351 ],\n",
       "       [  9.119392  ],\n",
       "       [  3.3976758 ],\n",
       "       [ 11.249509  ],\n",
       "       [ -1.8544129 ],\n",
       "       [103.09376   ],\n",
       "       [ -4.936814  ],\n",
       "       [  8.458381  ],\n",
       "       [  0.84915847],\n",
       "       [ 13.872462  ],\n",
       "       [  1.6011249 ],\n",
       "       [ 15.494536  ],\n",
       "       [ 49.42077   ],\n",
       "       [ 21.390764  ],\n",
       "       [ 14.245989  ],\n",
       "       [  3.816232  ],\n",
       "       [ 26.212023  ],\n",
       "       [ 11.871157  ],\n",
       "       [ -4.369931  ],\n",
       "       [ -2.0060403 ],\n",
       "       [  6.6783447 ],\n",
       "       [ 18.41554   ],\n",
       "       [160.05923   ],\n",
       "       [ 11.210517  ],\n",
       "       [ 15.351399  ]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f592711-d860-4e4a-8c82-8f5e1aab7075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 1), dtype=float32, numpy=\n",
       "array([[-20.85164  ],\n",
       "       [ -2.9716349],\n",
       "       [  4.684072 ],\n",
       "       [  5.127513 ],\n",
       "       [  5.8854237],\n",
       "       [-11.422145 ],\n",
       "       [  9.16414  ],\n",
       "       [-22.386084 ],\n",
       "       [  7.8355236],\n",
       "       [  8.873653 ],\n",
       "       [  3.5653758],\n",
       "       [  9.157463 ],\n",
       "       [  7.9223695],\n",
       "       [-13.675498 ],\n",
       "       [  8.801754 ],\n",
       "       [  8.186878 ],\n",
       "       [  3.9918492],\n",
       "       [  6.7647505],\n",
       "       [  5.0734725],\n",
       "       [  6.689303 ],\n",
       "       [  6.2356534],\n",
       "       [  6.0028753],\n",
       "       [ -5.9903064],\n",
       "       [-12.332437 ],\n",
       "       [-12.332856 ],\n",
       "       [  7.667494 ],\n",
       "       [  8.9350195],\n",
       "       [  8.143522 ],\n",
       "       [  8.997749 ],\n",
       "       [  8.389065 ],\n",
       "       [  3.9739268],\n",
       "       [  5.051523 ],\n",
       "       [119.30976  ],\n",
       "       [  8.425279 ],\n",
       "       [  7.1160355],\n",
       "       [129.44112  ],\n",
       "       [  4.004947 ],\n",
       "       [  4.441172 ],\n",
       "       [  4.3580017],\n",
       "       [  8.447446 ],\n",
       "       [  8.488038 ],\n",
       "       [ -3.9376974],\n",
       "       [ 99.32358  ],\n",
       "       [  9.137286 ],\n",
       "       [ -5.802184 ],\n",
       "       [129.28914  ],\n",
       "       [  8.664078 ],\n",
       "       [ -1.4089797],\n",
       "       [  6.4293914],\n",
       "       [ 99.32358  ],\n",
       "       [  6.1568007],\n",
       "       [  3.9756212],\n",
       "       [ 99.288376 ],\n",
       "       [-11.217665 ],\n",
       "       [-93.92757  ],\n",
       "       [-16.054327 ],\n",
       "       [  5.726613 ],\n",
       "       [  4.003938 ],\n",
       "       [  6.241995 ],\n",
       "       [ -4.4612126],\n",
       "       [ -0.8555563],\n",
       "       [ -0.8319897],\n",
       "       [  3.9341924],\n",
       "       [  6.7289114],\n",
       "       [  6.5236716],\n",
       "       [129.25043  ],\n",
       "       [-12.333494 ],\n",
       "       [  8.429342 ],\n",
       "       [  6.1420813],\n",
       "       [  6.457093 ],\n",
       "       [  6.4973426],\n",
       "       [-22.43096  ],\n",
       "       [  8.236978 ],\n",
       "       [  8.12134  ],\n",
       "       [-12.333797 ],\n",
       "       [  6.7886558],\n",
       "       [  5.227628 ],\n",
       "       [  6.917789 ],\n",
       "       [ -3.0269253],\n",
       "       [109.319496 ],\n",
       "       [-16.1414   ],\n",
       "       [129.23949  ],\n",
       "       [  8.230562 ],\n",
       "       [  6.104774 ],\n",
       "       [  6.5106277],\n",
       "       [-10.842509 ],\n",
       "       [ -6.0785913],\n",
       "       [  8.33355  ],\n",
       "       [  7.665159 ],\n",
       "       [  3.9396534],\n",
       "       [ -4.7498536],\n",
       "       [ 99.27207  ],\n",
       "       [  8.075082 ],\n",
       "       [  5.0453296],\n",
       "       [ -2.0243018],\n",
       "       [  4.3665857],\n",
       "       [  7.0202055],\n",
       "       [  6.984419 ],\n",
       "       [  3.9200938],\n",
       "       [ -3.5722063],\n",
       "       [-13.5071335],\n",
       "       [  7.8202987],\n",
       "       [  8.5367565],\n",
       "       [  6.6893387],\n",
       "       [  8.483404 ],\n",
       "       [ -3.3118973],\n",
       "       [  6.7672334],\n",
       "       [-21.787003 ],\n",
       "       [ 99.35735  ],\n",
       "       [  6.673081 ],\n",
       "       [ -3.2183735],\n",
       "       [  5.3198185],\n",
       "       [  6.8224244],\n",
       "       [  6.817209 ],\n",
       "       [  4.9035416],\n",
       "       [  9.0118685],\n",
       "       [  7.9011064],\n",
       "       [  7.166371 ],\n",
       "       [  5.9873934],\n",
       "       [  9.156269 ],\n",
       "       [  8.595667 ],\n",
       "       [-16.141401 ],\n",
       "       [-20.817701 ],\n",
       "       [  8.791023 ],\n",
       "       [  8.649671 ],\n",
       "       [129.4909   ],\n",
       "       [  8.617406 ],\n",
       "       [  7.04632  ]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426d597-b38c-44f5-9ff8-7e531b797d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
